# OpenCode 任务循环与上下文管理设计解析（Mini版）

## 一、核心问题

在开发一个 AI 编程助手时，我们需要解决以下核心问题：

1. **如何让 AI 持续工作？** - 用户说一句话，AI 就要做很多步操作
2. **如何管理长对话？** - 对话越来越长，LLM 有上下文限制
3. **如何安全地执行代码？** - AI 可能删除文件、执行危险命令
4. **如何处理工具调用？** - AI 需要读文件、写代码、执行命令

OpenCode 的设计围绕这些问题展开。

---

## 二、任务循环：让 AI 持续工作

### 2.1 是什么

任务循环是 OpenCode 的核心驱动机制：**一个 while(true) 无限循环**，负责不断接收用户消息、处理、与 LLM 交互，直到任务完成。

### 2.2 为什么需要它

LLM 是"一问一答"模式的，但编程任务是"多步操作"：

```
用户：帮我写一个 Todo 组件
AI：需要先看看项目结构
AI：找到了，这是 React 项目
AI：创建 Todo.tsx
AI：创建 Todo.test.tsx
AI：完成了！
```

这需要多次 LLM 调用，循环就是用来串联这些调用的。

### 2.3 设计思路

```
┌─────────────────────────────────────────────┐
│  loop() [无限循环]                           │
│  ┌─────────────────────────────────────┐    │
│  │ 1. 加载历史消息                      │    │
│  │ 2. 检查是否需要退出                  │    │
│  │ 3. 处理待办任务（子任务/压缩）        │    │
│  │ 4. 构建 Prompt                      │    │
│  │ 5. 调用 LLM                         │    │
│  │ 6. 处理响应（可能触发工具调用）       │    │
│  │ 7. 循环继续或终止                    │    │
│  └─────────────────────────────────────┘    │
└─────────────────────────────────────────────┘
```

### 2.4 核心逻辑（伪代码）

```typescript
while (true) {
  // 1. 加载历史消息
  const messages = loadMessages(sessionID)

  // 2. 检查是否需要退出
  if (isTaskCompleted(messages)) break

  // 3. 处理待办任务
  if (hasSubtask(messages)) { executeSubtask(); continue }
  if (needsCompaction(messages)) { compact(); continue }

  // 4. 构建 Prompt + 调用 LLM
  const response = callLLM({
    system: buildSystemPrompt(),
    messages: convertToLLMFormat(messages),
    tools: resolveTools()
  })

  // 5. 处理响应
  if (response.requestsTool) {
    executeTool(response.toolCall)
    // 工具结果会作为新消息加入历史，循环继续
    continue
  }

  // 6. 任务完成
  break
}
```

### 2.5 优缺点

| 优点        | 缺点                 |
| --------- | ------------------ |
| 简单直观，容易理解 | 无限循环需要正确退出条件       |
| 支持任意多步操作  | 中途取消需要 AbortSignal |
| 天然支持并发队列  | 状态管理复杂度较高          |

---

## 三、上下文管理：解决上下文限制

### 3.1 是什么

上下文管理是指：**如何组织、传递、压缩对话历史**，让 LLM 在长对话中始终能获取关键信息。

### 3.2 为什么需要它

LLM 有上下文窗口限制（如 200K tokens），但对话会越来越长：

```
第 1 轮对话：1K tokens
第 10 轮对话：50K tokens
第 50 轮对话：200K tokens（满了！）
```

### 3.3 设计思路：分层存储 + 动态压缩

```
┌────────────────────────────────────────────────────────────┐
│                      消息结构设计                           │
├────────────────────────────────────────────────────────────┤
│  Session（会话）                                            │
│  ├── Message（消息）                                        │
│  │   ├── User（用户消息）                                   │
│  │   │   └── Parts（文本、文件、Agent切换等）               │
│  │   └── Assistant（助手消息）                              │
│  │       └── Parts（文本、工具调用、推理过程等）             │
│  └── Parts 单独存储（支持增量更新）                         │
└────────────────────────────────────────────────────────────┘
```

### 3.4 消息 Part 设计

**为什么用 Part？**

单一消息可能包含多种内容：
- 用户说了一段话
- 附带了 3 个文件
- 还引用了一个 Agent

用 Part 统一处理这些异构内容。

```typescript
// Part 的类型
type Part =
  | TextPart        // 文本内容
  | ToolPart        // 工具调用
  | FilePart        // 文件附件
  | ReasoningPart   // 推理过程
  | SubtaskPart     // 子任务
  | CompactionPart  // 压缩标记
  | ...
```

### 3.5 上下文压缩策略

**触发条件**：当 tokens 接近模型限制时

```typescript
// 压缩判断
if (usedTokens > usableTokens) {
  triggerCompaction()
}
```

**压缩流程**：

```
压缩前：
[用户消息1][助手回复][工具结果][用户消息2][助手回复][工具结果]... [当前消息]

压缩后：
[摘要消息][用户消息2][助手回复][工具结果]... [当前消息]
```

**旧工具调用修剪**：

只保留最近 40K tokens 的工具调用详情，旧的标记为已压缩：

```
Old: "read file X returned 5000 lines..."
New: "[Old tool result content cleared]"
```

### 3.6 优缺点

| 优点 | 缺点 |
|------|------|
| Part 设计灵活，支持复杂消息 | 存储结构复杂 |
| 增量更新减少 IO | 压缩可能丢失细节 |
| 修剪策略节省空间 | 摘要质量依赖 LLM |

---

## 四、提示词构建：如何让 LLM 理解任务

### 4.1 是什么

提示词构建是：**将系统指令、环境信息、对话历史、可用工具组合成 LLM 认识的格式**。

### 4.2 为什么需要它

LLM 不"知道"：
- 它是什么角色（编程助手）
- 当前项目结构是什么
- 有哪些工具可以用
- 之前说了什么

这些都需要通过提示词告诉它。

### 4.3 设计思路：多层叠加

```
┌─────────────────────────────────────────────────────────┐
│                    提示词组成（从底到高）                 │
├─────────────────────────────────────────────────────────┤
│  1. Agent 提示词（最高优先级）                           │
│     "你是一个专业的前端开发者，擅长 React..."            │
├─────────────────────────────────────────────────────────┤
│  2. Provider 提示词（模型特定）                          │
│     Claude 有 Claude 的指导，GPT 有 GPT 的指导           │
├─────────────────────────────────────────────────────────┤
│  3. 环境信息                                             │
│     "工作目录: /project, Git: yes, 平台: macOS"         │
├─────────────────────────────────────────────────────────┤
│  4. 自定义提示词（用户/插件 注入）                       │
├─────────────────────────────────────────────────────────┤
│  5. 对话历史（格式化为 ModelMessage）                    │
│     [{"role":"user","content":"..."}, ...]              │
├─────────────────────────────────────────────────────────┤
│  6. 工具定义（按权限过滤后的）                           │
│     [{name:"read",description:"...",parameters:...}]    │
└─────────────────────────────────────────────────────────┘
```

### 4.4 消息格式转换

LLM 需要特定格式（如 OpenAI 的 format），OpenCode 需要把内部格式转换过去：

```
内部格式                              LLM 格式
┌──────────────────────┐         ┌──────────────────────┐
│ MessageV2            │  ──►    │ ModelMessage         │
│ ├─ role: user        │         │ ├─ role: user        │
│ ├─ parts[]           │         │ └─ content[]         │
│ │   ├─ TextPart      │         │    ├─ {type:text}     │
│ │   ├─ FilePart      │         │    ├─ {type:file}     │
│ │   └─ ToolPart      │         │    └─ {type:tool-*}  │
│ └─ ...               │         │                      │
└──────────────────────┘         └──────────────────────┘
```

**核心转换逻辑**：

```typescript
// 工具调用的转换
if (part.type === "tool" && part.state.status === "completed") {
  // LLM 看到的工具调用结果
  output.push({
    type: `tool-${part.tool}`,        // tool-read, tool-write...
    state: "output-available",
    toolCallId: part.callID,
    input: part.state.input,          // 调用的参数
    output: part.state.output,        // 执行结果
  })
}
```

### 4.5 优缺点

| 优点 | 缺点 |
|------|------|
| 多层叠加灵活可控 | 提示词可能过长 |
| 格式转换解耦 | 不同模型格式差异 |
| 插件可注入提示 | 需要维护多个提示词模板 |

---

## 五、工具系统：AI 的手和脚

### 5.1 是什么

工具系统让 LLM 能够执行真实操作：读文件、写代码、执行命令、搜索代码等。

### 5.2 为什么需要它

LLM 只能"说"，不能"做"。要让它真正帮我们编程，需要赋予它执行能力。

### 5.3 设计思路

```
┌─────────────────────────────────────────────────────────┐
│                    工具调用流程                          │
├─────────────────────────────────────────────────────────┤
│                                                         │
│  LLM: "我需要读取文件"                                   │
│       │                                                 │
│       ▼                                                 │
│  1. 解析 LLM 的工具调用请求                              │
│       │                                                 │
│       ▼                                                 │
│  2. 权限检查（这个 Agent 能用这个工具吗？）              │
│       │                                                 │
│       ├─ 拒绝 → 返回错误                                 │
│       ├─ 询问 → 暂停等待用户确认                         │
│       └─ 允许 → 继续                                     │
│       │                                                 │
│       ▼                                                 │
│  3. 执行工具（调用实际函数）                             │
│       │                                                 │
│       ▼                                                 │
│  4. 返回结果给 LLM                                      │
│       │                                                 │
│       ▼                                                 │
│  LLM: "文件内容是..."                                    │
│                                                         │
└─────────────────────────────────────────────────────────┘
```

### 5.4 权限系统

**设计理念**：默认拒绝，按需开放

```typescript
// Agent 的默认权限
const defaults = {
  "*": "allow",              // 大多数操作默认允许
  doom_loop: "ask",          // 循环执行要询问
  edit: { "*": "allow" },    // 编辑文件允许
  "*.env": { "*": "ask" },   // .env 文件要询问
  bash: { "*": "ask" },      // 执行命令要询问
}

// Plan Agent 的特殊权限（只读模式）
const planPermission = {
  edit: { "*": "deny" },     // 拒绝所有编辑
  question: "allow",         // 允许提问
}
```

**权限检查**：

```typescript
// 检查 Agent 是否有权限
const permission = PermissionNext.evaluate(agent, "bash", "rm -rf *")
if (permission.action === "deny") {
  throw new Error("Permission denied")
}
if (permission.action === "ask") {
  await askUser("AI wants to run: rm -rf *")
}
```

### 5.5 死循环检测

AI 可能陷入重复调用同一工具的陷阱：

```
read file A
read file A
read file A
read file A  ← 第 3 次，询问用户
```

**检测逻辑**：

```typescript
// 检查最近 3 次调用是否相同
const lastThree = getLastToolCalls(3)
if (allSameTool(lastThree) && allSameInput(lastThree)) {
  askUser("AI seems to be in a loop")
}
```

### 5.6 优缺点

| 优点 | 缺点 |
|------|------|
| 安全性高 | 频繁询问可能打扰用户 |
| 权限粒度细 | 配置复杂 |
| 支持任意扩展 | 权限冲突难以调试 |

---

## 六、数据流全景图

```
┌─────────────────────────────────────────────────────────────────────┐
│                          用户输入                                    │
└─────────────────────────────────────────────────────────────────────┘
                                 │
                                 ▼
┌─────────────────────────────────────────────────────────────────────┐
│                    createUserMessage()                              │
│  - 创建消息结构                                                      │
│  - 处理文件附件                                                      │
└─────────────────────────────────────────────────────────────────────┘
                                 │
                                 ▼
┌─────────────────────────────────────────────────────────────────────┐
│                    loop() [开始循环]                                 │
│                                                                     │
│  ┌───────────────────────────────────────────────────────────────┐  │
│  │ 1. loadMessages() - 从 Storage 加载历史消息                    │  │
│  │    ↓                                                          │  │
│  │ 2. filterCompacted() - 过滤已压缩的消息                        │  │
│  │    ↓                                                          │  │
│  │ 3. checkExit() - 检查是否需要退出                              │  │
│  │    ↓                                                          │  │
│  │ 4. buildPrompt() - 构建提示词                                  │  │
│  │    ├─ SystemPrompt.provider()                                 │  │
│  │    ├─ SystemPrompt.environment()                              │  │
│  │    ├─ MessageV2.toModelMessages()                             │  │
│  │    └─ resolveTools()                                          │  │
│  │    ↓                                                          │  │
│  │ 5. callLLM() - 调用 LLM                                        │  │
│  │    ↓                                                          │  │
│  │ 6. processResponse() - 处理流式响应                            │  │
│  │    ├─ text-delta → 显示文本                                    │  │
│  │    ├─ tool-call → 执行工具                                    │  │
│  │    └─ reasoning-delta → 显示推理                              │  │
│  │                                                                 │  │
│  │  [工具结果作为新消息加入历史，循环继续]                          │  │
│  └───────────────────────────────────────────────────────────────┘  │
│                                                                     │
└─────────────────────────────────────────────────────────────────────┘
                                 │
                                 ▼
┌─────────────────────────────────────────────────────────────────────┐
│                    任务完成或触发压缩                                 │
│                                                                     │
│  - 如果 tokens 溢出 → compact()                                      │
│    └─ 调用 LLM 生成摘要，标记旧消息已压缩                            │
│                                                                     │
│  - 如果 prune 触发                                                   │
│    └─ 标记旧工具调用内容为已压缩                                     │
│                                                                     │
└─────────────────────────────────────────────────────────────────────┘
```

---

## 七、核心设计模式总结

### 7.1 存储分层

```
Session（会话）┐
  ├─ Message（消息）┤
  │   └─ Part（片段）┘  ← 单独存储，支持增量更新
  └─ Message（消息）┘
```

**为什么？**
- Part 可能频繁更新（流式输出），单独存储避免整个消息重写
- 便于只加载需要的部分

### 7.2 消息流式读取

```typescript
// 从最新消息往回读
for (let i = list.length - 1; i >= 0; i--) {
  yield await getMessage(list[i])
}
```

**为什么倒序？**
- 最近的对话最重要，先处理
- 方便找到 `lastUser`、`lastAssistant`

### 7.3 并发队列

```typescript
// 同一个 session 同时多次调用
if (!abort) {
  return new Promise((resolve, reject) => {
    callbacks.push({ resolve, reject })  // 加入等待队列
  })
}
```

**为什么？**
- UI 可能有多个地方同时触发请求
- 让先到的等待，后到的排队

### 7.4 插件钩子

```typescript
// 在关键位置注入插件逻辑
await Plugin.trigger("tool.execute.before", {...}, { args })
await Plugin.trigger("tool.execute.after", {...}, result)
```

**为什么？**
- 让第三方扩展功能
- 无需修改核心代码

---

## 八、架构决策与权衡

| 决策 | 选择 | 权衡 |
|------|------|------|
| 循环控制 | while(true) + 状态判断 | 简单但需谨慎处理退出 |
| 消息存储 | Part 分离存储 | 增量更新好但复杂度高 |
| 上下文压缩 | LLM 摘要 + 标记压缩 | 节省空间但可能丢失信息 |
| 权限控制 | 默认拒绝 + 规则匹配 | 安全但配置复杂 |
| 工具执行 | 同步调用 | 简单但可能阻塞 |

---

## 九、关键文件清单

| 文件 | 职责 |
|------|------|
| `prompt.ts:259` | 主循环 loop() |
| `processor.ts:45` | LLM 响应处理 |
| `llm.ts:48` | 提示词构建、LLM 调用 |
| `message-v2.ts` | 消息数据结构、格式转换 |
| `compaction.ts` | 上下文压缩 |
| `system.ts` | 系统提示词模板 |
| `summary.ts` | 会话摘要生成 |

---

## 十、总结

OpenCode 的任务循环和上下文管理设计，围绕几个核心问题展开：

1. **持续工作**：用 while(true) 循环 + 退出条件控制
2. **长对话**：用 Part 结构 + 分层存储 + 动态压缩
3. **安全执行**：用权限系统 + 死循环检测
4. **工具调用**：用统一的工具接口 + 插件钩子

这套设计的核心思想是：
- **分层**：分离关注点（消息、工具、权限、压缩）
- **渐进**：默认安全，按需开放
- **可观测**：所有状态可追踪、可调试

---

*文档生成时间：2026-01-28*
*基于 vendors/opencode 源码分析*
